{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36836ad4-35bb-4d04-9118-170b1a3f37d1",
   "metadata": {},
   "source": [
    "### Task 0 Before your go\n",
    "\n",
    "> 1. Rename Assignment-02-###.ipynb where ### is your student ID.\n",
    "> 2. The deadline of Assignment-02 is 23:59pm, 04-21-2024\n",
    "> 3. In this assignment, you will use word embeddings to explore our Wikipedia dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec95d8-a23b-4116-8d00-197a049cfd4e",
   "metadata": {},
   "source": [
    "### Task 1 Train word embeddings using SGNS \n",
    "> Use our enwiki-train.json as training data. You can use the [Gensim tool](https://radimrehurek.com/gensim/models/word2vec.html). But it is recommended to implement by yourself. You should explain how hyper-parameters such as dimensionality of embeddings, window size, the parameter of negative sampling strategy, and initial learning rate have been chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baf0db53-3382-4534-b93e-e2a03796d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some necessary libraries\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import utils\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b61425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data from the json file\n",
    "\n",
    "# NOTE: The function is inherited from my solution of assignment 1\n",
    "def load_json(file_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Fetch the data from `.json` file and concat them into a list.\n",
    "\n",
    "    Input:\n",
    "    - file_path: The relative file path of the `.json` file\n",
    "\n",
    "    Returns:\n",
    "    - join_data_list: A list containing the data, with the format of [{'title':<>, 'label':<>, 'text':<>}, {}, ...]\n",
    "    \"\"\"\n",
    "    join_data_list = []\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        for line in json_file:\n",
    "            line = line.strip()\n",
    "            # guaranteen the line is not empty\n",
    "            if line: \n",
    "                join_data_list.append(json.loads(line))\n",
    "    return join_data_list\n",
    "\n",
    "train_file_path, test_file_path = \"enwiki-train.json\", \"enwiki-test.json\"\n",
    "train_data_list, test_data_list = map(load_json, [train_file_path, test_file_path])\n",
    "\n",
    "class Corpus:\n",
    "    def __iter__(self):\n",
    "        for line in train_data_list:\n",
    "            yield utils.simple_preprocess(line[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876121ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWord2Vec:\n",
    "    def __init__(self, text: List[dict], dimensionality: int=100, window_size: int=5, negative_samples: int=5, lr: float=0.001) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - text: The training data\n",
    "        - dimensionality: The dimension of the word embeddings\n",
    "        - window_size: The size of the context window\n",
    "        - negative_samples: The number of negative samples\n",
    "        - lr: Learning rate of the algorithm\n",
    "        \"\"\"\n",
    "        self.dim = dimensionality\n",
    "        self.window = window_size\n",
    "        self.neg = negative_samples\n",
    "        self.lr = lr\n",
    "        self.__vocab = set()\n",
    "        self.__word_frq = defaultdict(int)\n",
    "        self.__word2idx = {}\n",
    "        self.__idx2word = {}\n",
    "        self.__embedding = None\n",
    "        self.__context_words = []\n",
    "        self.__context_targets = []\n",
    "        self.__build(text)\n",
    "        \n",
    "\n",
    "    def __preprocess(self, text: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Calculate the vocabulary and the frequency of each word in the training data, while maintaining the (idx, word) map.\n",
    "        \"\"\"\n",
    "        for sample in text:\n",
    "            words = sample[\"text\"].split()\n",
    "            for word in words:\n",
    "                self.__vocab.add(word)\n",
    "                self.__word_frq[word] += 1\n",
    "        for idx, word in enumerate(self.__vocab):\n",
    "            self.__word2idx[word] = idx\n",
    "            self.__idx2word[idx] = word\n",
    "\n",
    "    def __generate_training_data(self, text: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Generate training data from each window and save them in `self.__context_words` and `self.__context_targets`\n",
    "        \"\"\"\n",
    "        for sample in text:\n",
    "            words = sample[\"text\"].split()\n",
    "            for i, curr_word in enumerate(words):\n",
    "                # the \"window\" around the current world\n",
    "                for j in range(max(0, i - self.window), min(i + self.window + 1, len(words))):\n",
    "                    if i != j:\n",
    "                        self.__context_words.append(self.__word2idx[curr_word])\n",
    "                        self.__context_targets.append(self.__word2idx[words[j]])\n",
    "\n",
    "    def __initialize_embedding(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the embedding matrix with random values\n",
    "        \"\"\"\n",
    "        self.__embedding = np.random.uniform(-0.5 / self.dim, 0.5 / self.dim, size=(len(self.__vocab), self.dim))\n",
    "    \n",
    "    def __build(self, text: List[map]) -> None:\n",
    "        \"\"\"\n",
    "        Compute and store the relevant information of the training data in the class\n",
    "        \"\"\"\n",
    "        self.__preprocess(text)\n",
    "        self.__generate_training_data(text)\n",
    "        self.__initialize_embedding()\n",
    "\n",
    "    def train(self, epochs: int=5) -> None: \n",
    "        for epoch in range(epochs):\n",
    "            # learning rate decay\n",
    "            learning_rate = self.lr * (1 - epoch / epochs)\n",
    "\n",
    "            print(\"Training Epoch: %d\" % (epoch + 1))\n",
    "\n",
    "            for context_word, target_word in zip(self.__context_words, self.__context_targets):\n",
    "                context_vector = self.__embedding[context_word]\n",
    "                target_vector = self.__embedding[target_word]\n",
    "\n",
    "                # positive sample update\n",
    "                score = np.dot(target_vector, context_vector)\n",
    "                exp_score = math.exp(score)\n",
    "                grad_context = (exp_score / (1 + exp_score) - 1) * target_vector\n",
    "                grad_target = (exp_score / (1 + exp_score) - 1) * context_vector\n",
    "                self.__embedding[context_word] -= learning_rate * grad_context\n",
    "                self.__embedding[target_word] -= learning_rate * grad_target\n",
    "\n",
    "                # negative sample update\n",
    "                for _ in range(self.neg):\n",
    "                    negative_word = random.randint(0, len(self.__vocab) - 1)\n",
    "                    if negative_word != target_word:\n",
    "                        negative_vector = self.__embedding[negative_word]\n",
    "                        score = np.dot(negative_vector, context_vector)\n",
    "                        exp_score = math.exp(score)\n",
    "                        grad_context = exp_score / (1 + exp_score) * negative_vector\n",
    "                        grad_target = exp_score / (1 + exp_score) * context_vector\n",
    "                        self.__embedding[context_word] -= learning_rate * grad_context\n",
    "                        self.__embedding[target_word] -= learning_rate * grad_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286cfc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Corpus()\n",
    "model = Word2Vec(\n",
    "    sentences=sentence, vector_size=100, alpha=0.025, window=5, min_count=5, sample=0.001, \n",
    "    seed=1, workers=3, min_alpha=0.0001, sg=1, negative=5, ns_exponent=0.75, epochs=5, \n",
    "    sorted_vocab=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeadc4b2-2c39-46f1-a9b9-28089393c24f",
   "metadata": {},
   "source": [
    "### Task 2 Find similar/dissimilar word pairs\n",
    "\n",
    "> Randomly generate 100, 1000, and 10000-word pairs from the vocabularies. For each set, print 5 closest word pairs and 5 furthest word pairs (you can use cosine-similarity to measure two words). Explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81f7d38-0bf0-4e55-aedc-b0f8f24195f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For   100 random pairs from the vocabularies:\n",
      "The 5  closest word pairs:\n",
      "Word pairs: (      herodotus,       sorcerers) --> Similarity: 0.880446\n",
      "Word pairs: (stereotypically,             een) --> Similarity: 0.842470\n",
      "Word pairs: (        bruxing,        plumbers) --> Similarity: 0.839791\n",
      "Word pairs: (           sown,     prohibitive) --> Similarity: 0.833044\n",
      "Word pairs: (         shaded,           booby) --> Similarity: 0.825319\n",
      "The 5 furthest word pairs:\n",
      "Word pairs: (         member,        investor) --> Similarity: 0.233117\n",
      "Word pairs: (          harry,           kuala) --> Similarity: 0.231424\n",
      "Word pairs: (        trapped,          arabia) --> Similarity: 0.216789\n",
      "Word pairs: (       superman,         outputs) --> Similarity: 0.189746\n",
      "Word pairs: (     separately,       communism) --> Similarity: 0.149030\n",
      "----------------------------------------------------------------------\n",
      "For  1000 random pairs from the vocabularies:\n",
      "The 5  closest word pairs:\n",
      "Word pairs: (        itching,         dryness) --> Similarity: 0.906004\n",
      "Word pairs: (     inaugurate,         dumping) --> Similarity: 0.904958\n",
      "Word pairs: (        serrano,    englishwoman) --> Similarity: 0.901307\n",
      "Word pairs: (      datatypes,        suvorova) --> Similarity: 0.886079\n",
      "Word pairs: (       armature,       filaments) --> Similarity: 0.882169\n",
      "The 5 furthest word pairs:\n",
      "Word pairs: (     philippine,     inspiration) --> Similarity: 0.067479\n",
      "Word pairs: (         bought,        numbness) --> Similarity: 0.052801\n",
      "Word pairs: (         lucien,     regulations) --> Similarity: 0.050545\n",
      "Word pairs: (        teenage,           pages) --> Similarity: 0.005215\n",
      "Word pairs: (           duff,           saccà) --> Similarity: -0.023395\n",
      "----------------------------------------------------------------------\n",
      "For 10000 random pairs from the vocabularies:\n",
      "The 5  closest word pairs:\n",
      "Word pairs: (          chaat,          capers) --> Similarity: 0.954008\n",
      "Word pairs: (    autocorrect,           addon) --> Similarity: 0.941513\n",
      "Word pairs: (        crumbly,          yakhni) --> Similarity: 0.930134\n",
      "Word pairs: (        outflow,          efflux) --> Similarity: 0.914117\n",
      "Word pairs: (     elliptical,         spicule) --> Similarity: 0.912141\n",
      "The 5 furthest word pairs:\n",
      "Word pairs: (  vulnerability,         honneur) --> Similarity: -0.038952\n",
      "Word pairs: (    lymphocytes,          sunday) --> Similarity: -0.039077\n",
      "Word pairs: (  misconception,           vilma) --> Similarity: -0.065047\n",
      "Word pairs: (        manotoc,       cluttered) --> Similarity: -0.089658\n",
      "Word pairs: (      longridge,      projectile) --> Similarity: -0.090173\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generate_random_paris(samples: int):\n",
    "    \"\"\"\n",
    "    Generate random indices without replacement, then pairs the indices to get word pairs\n",
    "    \"\"\"\n",
    "    indices = random.sample(range(len(model.wv)), 2 * samples)\n",
    "    indices1, indices2 = indices[:samples], indices[samples:]\n",
    "    return [model.wv.index_to_key[i] for i in indices1], [model.wv.index_to_key[i] for i in indices2]\n",
    "\n",
    "def find_closest_furthest(num: int=5, words1: List[str]=None, words2: List[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    Find the cloest/furthest word pairs using `model.wv.similarity`.\n",
    "\n",
    "    Here a heap queue is used to reduce time complexity to $O(n\\log k)$, where k denotes the `num`\n",
    "    \"\"\"\n",
    "    heap = []\n",
    "    for i in range(len(words1)):\n",
    "        # compute the similarity and push it into the heap\n",
    "        heapq.heappush(heap, (model.wv.similarity(words1[i], words2[i]), words1[i], words2[i]))\n",
    "    return heapq.nlargest(num, heap), heapq.nsmallest(num, heap)[::-1]\n",
    "\n",
    "def print_word_pairs(results: List[tuple], flag: str) -> None:\n",
    "    \"\"\"\n",
    "    Print the result in formatted string\n",
    "    \"\"\"\n",
    "    print(\"The 5 {:>8} word pairs:\".format(flag))\n",
    "    for result in results:\n",
    "       print(\"Word pairs: ({:>15}, {:>15}) --> Similarity: {:>8.6f}\".format(result[1], result[2], result[0]))\n",
    "\n",
    "\n",
    "random.seed(408)\n",
    "pairs = [100, 1000, 10000]\n",
    "for pair in pairs:\n",
    "    print(\"For {:>5} random pairs from the vocabularies:\".format(pair))\n",
    "    cloest, furthest = find_closest_furthest(5, *generate_random_paris(pair))\n",
    "    print_word_pairs(cloest, \"closest\")\n",
    "    print_word_pairs(furthest, \"furthest\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af756bde-2960-4c56-b037-0bfd2cf7e47e",
   "metadata": {},
   "source": [
    "### Task 3 Present a document as an embedding\n",
    "\n",
    "> For each document, you have several choices to generate document embedding: 1. Use the average of embeddings of all words in each document; 2. Use the first paragraph’s words and take an average on these embeddings; 3. Use the doc2vec algorithm to present each document. Do the above for both training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279547d8-e4e7-4bfa-9be9-6d535b86bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citizen_Kane:\n",
      "[-0.18555687 -0.11498394  0.12703045  0.19868466 -0.08605349 -0.3689179\n",
      "  0.21345545  0.31779507 -0.16548374 -0.25047037 -0.00524598 -0.33721638\n",
      "  0.00063661  0.08648021  0.01215639 -0.0763451   0.30754155  0.08644778\n",
      " -0.04686667 -0.37171257 -0.14886318  0.14374806  0.09710665 -0.04084833\n",
      "  0.03245828  0.13903828 -0.27641234  0.1391886  -0.13908271 -0.18599151\n",
      " -0.17242636  0.12265657 -0.09491661  0.02495716 -0.07464156  0.11531783\n",
      " -0.12658444 -0.2402224  -0.12558994 -0.13856143 -0.0395303  -0.08800881\n",
      " -0.30476314 -0.13202067  0.17026316  0.02671698 -0.21354283  0.05506658\n",
      "  0.19191238  0.02331443  0.11432122 -0.01052564 -0.28179178 -0.06251904\n",
      " -0.07604388 -0.03214294 -0.13627957 -0.02698852 -0.00246957  0.13575526\n",
      "  0.15388337  0.11309912  0.18228544  0.01188574 -0.00392627  0.07238039\n",
      " -0.03351165  0.2826619  -0.25783497  0.19132069  0.21434167  0.260049\n",
      "  0.02967949 -0.01430467  0.15401529  0.22354499 -0.05086841  0.13207738\n",
      "  0.19135456 -0.03810756 -0.18478478 -0.1590119   0.18383226  0.10540011\n",
      "  0.07999206  0.04714241 -0.00204678  0.08591481  0.0554568   0.17360328\n",
      "  0.24782184  0.0572723   0.22145666 -0.35413817 -0.08483081  0.12416708\n",
      " -0.06020156 -0.31735036  0.08504955  0.01121635]\n",
      "----------------------------------------------------------------------\n",
      "It_(2017_film):\n",
      "[-0.20847543 -0.14206445  0.12077957  0.21345885 -0.10133104 -0.32528368\n",
      "  0.17333971  0.327367   -0.18686642 -0.24941634 -0.00723189 -0.3698569\n",
      " -0.01496399  0.10402453  0.027485   -0.07448909  0.33939958  0.10233012\n",
      " -0.04705502 -0.3986012  -0.1491188   0.12218845  0.09381118 -0.02042187\n",
      "  0.03483624  0.1022433  -0.2798671   0.1023089  -0.13507672 -0.19560613\n",
      " -0.1423029   0.12463772 -0.07813394  0.01258673 -0.12711897  0.09718475\n",
      " -0.11311155 -0.26027894 -0.11584783 -0.13625075 -0.00409492 -0.09629755\n",
      " -0.26816657 -0.15263297  0.18252133  0.04292414 -0.20487307  0.04854682\n",
      "  0.24196804 -0.00055938  0.0888538  -0.02866241 -0.2866841  -0.08492528\n",
      " -0.04458309  0.01039274 -0.15857345 -0.03198382 -0.00357151  0.13786933\n",
      "  0.16019557  0.13139987  0.21482289  0.00520191 -0.01796972  0.06494526\n",
      " -0.03507071  0.3030891  -0.2557795   0.20060952  0.18666653  0.27546877\n",
      "  0.02517258 -0.02225168  0.19194248  0.21877524 -0.00385116  0.12176304\n",
      "  0.15847252 -0.03113813 -0.18485261 -0.13700475  0.17287497  0.15456249\n",
      "  0.11068742  0.03127877 -0.00623719  0.05256742  0.05544978  0.18323837\n",
      "  0.23264445  0.06423082  0.17058615 -0.3582281  -0.09601139  0.11186024\n",
      " -0.04482519 -0.3168518   0.09628797  0.01284159]\n",
      "----------------------------------------------------------------------\n",
      "Star_Wars_(film):\n",
      "[-0.2130418  -0.0971953   0.125019    0.20510396 -0.06686969 -0.33610037\n",
      "  0.1866534   0.33981273 -0.16301683 -0.3089765  -0.00163018 -0.36281845\n",
      "  0.00760081  0.09125994  0.014876   -0.09598538  0.30667675  0.08500479\n",
      " -0.06345256 -0.37944746 -0.12177417  0.15778278  0.11012731 -0.06334438\n",
      "  0.02464989  0.11301981 -0.26860526  0.11112053 -0.15059559 -0.19493234\n",
      " -0.18503337  0.11139964 -0.08818608  0.02156892 -0.08945245  0.10143565\n",
      " -0.13000971 -0.24973439 -0.11266707 -0.13792598  0.0129382  -0.06874689\n",
      " -0.3212263  -0.12022179  0.1602723   0.03249883 -0.21442975  0.05863944\n",
      "  0.22663747  0.02304714  0.1203606  -0.03109855 -0.2600529  -0.06884299\n",
      " -0.06120989 -0.01236999 -0.13193853 -0.05303753 -0.00109716  0.12702942\n",
      "  0.17716631  0.12921245  0.18835977 -0.0347269  -0.01783548  0.06741858\n",
      " -0.06037254  0.3026438  -0.23399974  0.16063428  0.19954987  0.2301007\n",
      "  0.04328235 -0.04680185  0.14336209  0.19289626 -0.04040828  0.12597834\n",
      "  0.15639438 -0.04268201 -0.1603822  -0.15188421  0.18597402  0.13455376\n",
      "  0.11934438  0.04922261 -0.01355522  0.05826371  0.03621626  0.16087851\n",
      "  0.25897     0.04768439  0.21171555 -0.35481635 -0.09068535  0.10578822\n",
      " -0.06571494 -0.3163387   0.07685124  0.00258483]\n",
      "----------------------------------------------------------------------\n",
      "Star_Trek:_The_Motion_Picture:\n",
      "[-2.14111924e-01 -9.58134681e-02  9.47187096e-02  1.76840231e-01\n",
      " -6.76426217e-02 -3.02146584e-01  1.66172132e-01  3.33211064e-01\n",
      " -1.63884953e-01 -2.96406627e-01  1.12524000e-03 -3.34022671e-01\n",
      " -5.17369341e-03  1.21238239e-01  7.43458234e-03 -8.30062553e-02\n",
      "  3.11201334e-01  1.24022529e-01 -8.69646370e-02 -3.83331478e-01\n",
      " -1.30661085e-01  1.53037339e-01  9.83313397e-02 -4.92377505e-02\n",
      "  1.96886212e-02  9.75414440e-02 -2.87359864e-01  1.17678091e-01\n",
      " -1.20243400e-01 -1.87377036e-01 -1.98497549e-01  1.31688714e-01\n",
      " -1.17096327e-01 -1.02217477e-02 -6.20640144e-02  1.13507397e-01\n",
      " -1.19550951e-01 -2.49585554e-01 -9.10812095e-02 -1.43597424e-01\n",
      " -1.70466024e-02 -5.39805442e-02 -3.25318754e-01 -1.44048139e-01\n",
      "  1.62162751e-01  1.63829401e-02 -2.17544124e-01  6.46135360e-02\n",
      "  2.36722901e-01  1.34008443e-02  1.08556949e-01 -3.97789739e-02\n",
      " -2.98392296e-01 -6.63532838e-02 -7.02760816e-02 -1.26986171e-03\n",
      " -1.38194919e-01 -5.95385432e-02 -1.68102342e-05  1.44638821e-01\n",
      "  2.10734829e-01  8.11848640e-02  1.95526391e-01 -8.88746977e-03\n",
      " -2.15760227e-02  6.54377118e-02 -4.31899317e-02  3.12188447e-01\n",
      " -2.53809363e-01  1.57384723e-01  1.77505940e-01  2.39432156e-01\n",
      "  3.95485871e-02 -4.84482870e-02  1.63065031e-01  2.17931867e-01\n",
      " -3.85773145e-02  1.03520662e-01  1.73123837e-01 -8.26694369e-02\n",
      " -1.73108235e-01 -1.50710747e-01  1.94007143e-01  1.36711076e-01\n",
      "  1.53380200e-01  5.05579785e-02  9.80123132e-03  5.09596914e-02\n",
      "  1.75204147e-02  1.68885335e-01  2.60076195e-01  2.59084255e-02\n",
      "  1.90662786e-01 -3.60166460e-01 -8.06472823e-02  1.07512094e-01\n",
      " -8.81111994e-02 -3.41086060e-01  6.31479099e-02  5.07018901e-02]\n",
      "----------------------------------------------------------------------\n",
      "Frozen_(2013_film):\n",
      "[-0.22333632 -0.09566829  0.11785875  0.20374134 -0.09935971 -0.35305005\n",
      "  0.17328556  0.33454722 -0.18932953 -0.28225642  0.00224698 -0.36933985\n",
      " -0.00907213  0.07069452  0.0095383  -0.09014443  0.31511226  0.08836993\n",
      " -0.07067346 -0.37025684 -0.12611856  0.11327616  0.09886232 -0.05983797\n",
      "  0.04316757  0.11176693 -0.2661031   0.1210103  -0.1355327  -0.21139283\n",
      " -0.16052067  0.11398538 -0.06718447 -0.01712907 -0.09639294  0.08949184\n",
      " -0.11087006 -0.24657293 -0.10810433 -0.14502068  0.01383213 -0.06568218\n",
      " -0.30306116 -0.13309589  0.19130613  0.04153097 -0.22976868  0.05635783\n",
      "  0.23144901  0.02224504  0.10243796 -0.02831227 -0.28908694 -0.08387195\n",
      " -0.03777696 -0.01359564 -0.14152823 -0.02723882 -0.00267493  0.13219956\n",
      "  0.16943388  0.14506698  0.20105536 -0.01988265 -0.01967399  0.06427592\n",
      " -0.04365128  0.3339629  -0.25448865  0.18226492  0.19723685  0.2450251\n",
      "  0.01685477 -0.02911355  0.1528494   0.2038489  -0.03660947  0.13886416\n",
      "  0.13892391 -0.02032    -0.15161549 -0.15422742  0.20058538  0.14551792\n",
      "  0.11639654  0.04833587 -0.02614503  0.07566257  0.04952805  0.1688343\n",
      "  0.22889498  0.04867182  0.18005647 -0.36922404 -0.10935488  0.10019334\n",
      " -0.05721905 -0.31366503  0.08246516  0.00512623]\n",
      "----------------------------------------------------------------------\n",
      "Black_Panther_(film):\n",
      "[-2.14866817e-01 -9.91178825e-02  1.42255157e-01  1.99574634e-01\n",
      " -8.82877931e-02 -3.53495210e-01  1.68079630e-01  3.39112341e-01\n",
      " -2.18038365e-01 -3.12220514e-01  1.28835402e-02 -3.80374223e-01\n",
      "  2.65661422e-02  9.04773474e-02  2.85729077e-02 -7.69806504e-02\n",
      "  3.08225453e-01  7.74253234e-02 -5.65026775e-02 -3.55214983e-01\n",
      " -1.02979779e-01  1.20754994e-01  1.04782633e-01 -6.90167695e-02\n",
      "  2.59237587e-02  8.68569911e-02 -2.69013554e-01  1.29367754e-01\n",
      " -1.47864923e-01 -1.73551276e-01 -1.61437497e-01  1.21737003e-01\n",
      " -7.20365867e-02  6.34616613e-03 -8.17891732e-02  8.48101825e-02\n",
      " -1.00623392e-01 -2.75919825e-01 -9.61714908e-02 -1.49139240e-01\n",
      "  1.60311535e-02 -5.49007691e-02 -3.06207240e-01 -1.42386734e-01\n",
      "  1.76327497e-01  3.61648798e-02 -1.97987139e-01  9.27925110e-02\n",
      "  2.31592596e-01  1.10515039e-02  1.19545713e-01 -1.20485164e-02\n",
      " -2.68264771e-01 -6.42693862e-02 -7.93783441e-02 -2.83923117e-04\n",
      " -1.62485763e-01 -2.87022553e-02  2.04147641e-02  1.05067462e-01\n",
      "  1.99791670e-01  1.53894305e-01  2.07585260e-01 -8.84176977e-03\n",
      " -1.26777925e-02  8.13669339e-02 -2.93876845e-02  3.54863763e-01\n",
      " -2.64210492e-01  1.52440086e-01  2.22968802e-01  2.21217468e-01\n",
      "  4.40764688e-02 -3.62388417e-02  1.56617612e-01  1.99818835e-01\n",
      " -1.27951680e-02  1.28145233e-01  1.43914253e-01 -2.36264281e-02\n",
      " -1.60480902e-01 -1.60718665e-01  1.80876240e-01  1.46208093e-01\n",
      "  1.15746759e-01  3.93088199e-02 -1.36637175e-02  3.86801325e-02\n",
      "  3.35924514e-02  1.58135667e-01  2.21321285e-01  5.17544784e-02\n",
      "  2.02243134e-01 -3.42900246e-01 -9.39792618e-02  1.07198276e-01\n",
      " -5.76359071e-02 -3.11905205e-01  6.72791600e-02  9.97004472e-03]\n",
      "----------------------------------------------------------------------\n",
      "The_Cabinet_of_Dr._Caligari:\n",
      "[-0.18406892 -0.15793572  0.15798648  0.19864781 -0.0853647  -0.34517047\n",
      "  0.23454592  0.35116315 -0.13432583 -0.2523329  -0.02654897 -0.3302878\n",
      " -0.00540284  0.13102707 -0.00467377 -0.03958759  0.34765744  0.11030372\n",
      " -0.07064169 -0.37349576 -0.1681924   0.12563966  0.11077739 -0.03770708\n",
      " -0.00418837  0.12470435 -0.25692165  0.1073979  -0.16561683 -0.1726131\n",
      " -0.18170059  0.10487264 -0.07585718  0.01101494 -0.09774825  0.07156137\n",
      " -0.08473535 -0.2907065  -0.12365791 -0.12334062 -0.01311064 -0.07441422\n",
      " -0.26622388 -0.14683855  0.17220284  0.03593657 -0.2175906   0.05886851\n",
      "  0.23207015  0.05690956  0.11205475 -0.02769461 -0.27548665 -0.08568448\n",
      " -0.07609555  0.0093638  -0.18430541 -0.04225655  0.02311677  0.15700817\n",
      "  0.1762853   0.0775418   0.18735485  0.00496186 -0.00999759  0.06679934\n",
      " -0.05718154  0.29432702 -0.27853602  0.14919147  0.1975752   0.26188168\n",
      "  0.04093789 -0.04931591  0.12987684  0.21423192 -0.01972903  0.10778339\n",
      "  0.1825358  -0.00376631 -0.20560995 -0.16331282  0.1922769   0.12440778\n",
      "  0.07564197  0.00965907 -0.01627678  0.04935813  0.0590948   0.18941617\n",
      "  0.19935994  0.03212193  0.20862646 -0.35763845 -0.04624293  0.15958554\n",
      " -0.07953924 -0.31987584  0.10040324  0.03718241]\n",
      "----------------------------------------------------------------------\n",
      "The_Shining_(film):\n",
      "[-1.93494037e-01 -1.55416042e-01  1.28517717e-01  2.26515099e-01\n",
      " -8.99870023e-02 -3.48037690e-01  2.22423822e-01  3.54270458e-01\n",
      " -1.69151947e-01 -2.65848041e-01 -1.79564655e-02 -3.40396464e-01\n",
      " -2.37218048e-02  9.42575634e-02  4.59435023e-03 -4.46510948e-02\n",
      "  3.33704144e-01  1.02538861e-01 -5.69104329e-02 -3.93927425e-01\n",
      " -1.67946234e-01  1.33661062e-01  9.32331160e-02 -1.99989323e-02\n",
      "  4.29198379e-03  1.00570783e-01 -2.81522006e-01  1.13152474e-01\n",
      " -1.41099498e-01 -1.89585388e-01 -1.64194033e-01  1.24199867e-01\n",
      " -7.28071108e-02  2.49701720e-02 -1.17452696e-01  8.92345384e-02\n",
      " -1.10935844e-01 -2.59919673e-01 -1.16821580e-01 -1.21019974e-01\n",
      " -1.39728338e-02 -8.62134770e-02 -2.56694466e-01 -1.41494185e-01\n",
      "  1.90396711e-01  4.57341596e-02 -2.04915926e-01  3.04807350e-02\n",
      "  2.27972597e-01  3.45736891e-02  9.55918357e-02 -4.98650111e-02\n",
      " -2.91775376e-01 -9.43654701e-02 -5.58917895e-02  3.74916568e-03\n",
      " -1.68019131e-01 -5.56156486e-02  1.68817956e-02  1.43654913e-01\n",
      "  1.54758602e-01  1.16333425e-01  1.93168670e-01 -7.77842710e-03\n",
      " -2.06436757e-02  9.23201069e-02 -5.75757809e-02  2.87639469e-01\n",
      " -2.38640100e-01  1.59801260e-01  1.92855820e-01  2.79989898e-01\n",
      "  3.04153264e-02 -3.20995301e-02  1.68044761e-01  2.12408856e-01\n",
      "  2.53764272e-04  1.01303875e-01  1.66422009e-01 -1.26585513e-02\n",
      " -1.90389544e-01 -1.29843220e-01  1.60506099e-01  1.34985328e-01\n",
      "  8.85573104e-02  6.55196607e-03 -1.78683177e-02  4.20056619e-02\n",
      "  3.78371924e-02  1.86042920e-01  2.21264273e-01  5.17788492e-02\n",
      "  2.09680572e-01 -3.53284478e-01 -7.73227364e-02  1.47503093e-01\n",
      " -7.36587644e-02 -3.13822776e-01  1.08031087e-01  1.34655656e-02]\n",
      "----------------------------------------------------------------------\n",
      "Scream_(franchise):\n",
      "[-0.23633333 -0.14580636  0.11275064  0.21979544 -0.09968454 -0.36690775\n",
      "  0.20317902  0.32033914 -0.18378337 -0.3029338   0.00643857 -0.37274334\n",
      "  0.01059036  0.06039896  0.00542999 -0.10295279  0.2912581   0.08180309\n",
      " -0.04559388 -0.35556427 -0.14606538  0.1330834   0.10462752 -0.05093824\n",
      "  0.04790461  0.14697954 -0.30459276  0.10933185 -0.13769965 -0.20636484\n",
      " -0.16050096  0.14027229 -0.074538   -0.00680345 -0.07264975  0.11132714\n",
      " -0.13287261 -0.27362612 -0.14126368 -0.14159149 -0.00068811 -0.04872854\n",
      " -0.31197506 -0.12127256  0.17452683  0.02775808 -0.21076708  0.07267624\n",
      "  0.19878568  0.01679232  0.12860362 -0.00737905 -0.28293738 -0.03475743\n",
      " -0.05551383 -0.01461639 -0.12030133 -0.05055684 -0.00529533  0.10893181\n",
      "  0.15633534  0.13121924  0.19372742 -0.02444649 -0.01296553  0.06293643\n",
      " -0.07322874  0.2929703  -0.23051327  0.16306993  0.18601969  0.27147496\n",
      "  0.01336654 -0.05350569  0.16334417  0.22595939 -0.03823617  0.12019374\n",
      "  0.17089987 -0.01383135 -0.17015986 -0.17562528  0.19870557  0.12217577\n",
      "  0.13034275  0.04856373 -0.04158871  0.06799425  0.07873642  0.1945954\n",
      "  0.22116251  0.0543585   0.20682225 -0.3684101  -0.10116124  0.10314338\n",
      " -0.08824866 -0.31784254  0.07819387  0.03447232]\n",
      "----------------------------------------------------------------------\n",
      "Batman_v_Superman:_Dawn_of_Justice:\n",
      "[-0.2253818  -0.13300723  0.11963817  0.22049545 -0.10129456 -0.3340705\n",
      "  0.19471025  0.3464951  -0.20928723 -0.2752074   0.00818669 -0.39991495\n",
      "  0.0056403   0.06467348  0.03278836 -0.09939507  0.29897848  0.07936467\n",
      " -0.03607916 -0.3792399  -0.15673715  0.11320235  0.10005347 -0.02367146\n",
      "  0.01755605  0.08379582 -0.27072808  0.1021912  -0.15166709 -0.19126186\n",
      " -0.14044696  0.12464871 -0.058593    0.03775037 -0.12300595  0.09711871\n",
      " -0.10485951 -0.24979499 -0.11602722 -0.13908702  0.01563336 -0.08349042\n",
      " -0.27383888 -0.11731423  0.16678785  0.04681058 -0.2046353   0.0728025\n",
      "  0.23444557  0.00611837  0.0996571   0.02444164 -0.25340834 -0.07553734\n",
      " -0.06242155  0.02878139 -0.14205591 -0.03304495  0.01184042  0.13732813\n",
      "  0.17231546  0.15045938  0.20481972 -0.03901973 -0.02297649  0.09168172\n",
      " -0.06444205  0.3164135  -0.24871038  0.19057305  0.2037765   0.24990147\n",
      "  0.01983249 -0.02096898  0.19453172  0.22248216  0.01345577  0.12596026\n",
      "  0.15155727 -0.02874724 -0.1697489  -0.15286915  0.1619284   0.15694514\n",
      "  0.09971548  0.03630242 -0.01295955  0.03582918  0.04113824  0.15431301\n",
      "  0.2207257   0.07368174  0.19505288 -0.3453157  -0.07558191  0.09572735\n",
      " -0.05453224 -0.2916435   0.08002821 -0.01496465]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "###        1. Use the average of embeddings of all words in each document        ###\n",
    "####################################################################################\n",
    "def print_document_embeddings(embeddings: dict, display: int=10) -> None:\n",
    "    \"\"\"\n",
    "    Print the first `display` embeddings, default value is 10\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for title, embedding in embeddings.items():\n",
    "        if count >= display:\n",
    "            break\n",
    "        count += 1\n",
    "        print(\"{}:\\n{}\".format(title, embedding))\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "def average_all_words() -> dict:\n",
    "    doc_embeddings = {}\n",
    "    for line in train_data_list:\n",
    "        line_text = utils.simple_preprocess(line[\"text\"]) # preprocess the text as in class `Corpus`\n",
    "        # doc title and doc embedding computed by averaging all words embeddings\n",
    "        doc_title = line[\"title\"]\n",
    "        valid_word_embeddings = [model.wv[word] for word in line_text if word in model.wv]\n",
    "        doc_embedding = sum(valid_word_embeddings) / len(valid_word_embeddings)\n",
    "        # store the information in a dictionary\n",
    "        doc_embeddings[doc_title] = doc_embedding\n",
    "\n",
    "    return doc_embeddings\n",
    "\n",
    "average_all_words_embedding = average_all_words()\n",
    "print_document_embeddings(average_all_words_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ae2cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citizen_Kane:\n",
      "[-0.23090884 -0.13291559  0.20529905  0.21812418 -0.0190186  -0.4826053\n",
      "  0.24806686  0.25670743 -0.22496761 -0.26894984 -0.00441595 -0.3581196\n",
      "  0.02116748  0.00248322  0.0051759  -0.14579874  0.2945101  -0.01452728\n",
      " -0.00802334 -0.3153541  -0.20796755  0.19100672  0.05338027 -0.13419762\n",
      " -0.01046245  0.10917778 -0.3302613   0.12475839 -0.21306188 -0.17888463\n",
      " -0.1695718   0.10462276 -0.1263146   0.06113715 -0.04916075  0.16068289\n",
      " -0.22512802 -0.2268536  -0.17277665 -0.1014448  -0.01882456 -0.13939385\n",
      " -0.31199345 -0.08741815  0.14783925  0.05809337 -0.19782293  0.07757351\n",
      "  0.10127524  0.07007059  0.18039902 -0.02828163 -0.2131288  -0.06944453\n",
      " -0.14726196 -0.15870269 -0.10337288 -0.01378004  0.04356508  0.10337719\n",
      "  0.19568619  0.19663046  0.22753777 -0.00818827 -0.03096233  0.06069575\n",
      " -0.0204902   0.29396346 -0.26438767  0.21963672  0.20457593  0.23003624\n",
      "  0.08429366 -0.01530797  0.11847984  0.21866457 -0.05647788  0.19103517\n",
      "  0.16344292 -0.00218383 -0.11557421 -0.17521183  0.1880264   0.00496392\n",
      "  0.04700921  0.06610683 -0.07243365  0.07350183  0.1199524   0.19234885\n",
      "  0.29530632  0.00771779  0.2096873  -0.32158473 -0.14417547  0.07983211\n",
      " -0.10923193 -0.3334386   0.08297948  0.00681338]\n",
      "----------------------------------------------------------------------\n",
      "It_(2017_film):\n",
      "[-0.219959   -0.16542955  0.12892278  0.26278967 -0.09142552 -0.4060823\n",
      "  0.22560237  0.35678458 -0.20380421 -0.31528613  0.04511894 -0.35671958\n",
      " -0.03833762  0.05418783  0.02702839 -0.03646692  0.30497712  0.05222804\n",
      " -0.05962589 -0.34482    -0.19996448  0.09609409  0.1447968  -0.06374563\n",
      "  0.00989145  0.12534904 -0.2678609   0.16779527 -0.20003566 -0.23944487\n",
      " -0.15400489  0.10669491 -0.06228593 -0.02360652 -0.09730651  0.07424617\n",
      " -0.14299545 -0.24661213 -0.13646969 -0.11161075  0.06143859 -0.10246725\n",
      " -0.26313874 -0.05986152  0.14016306  0.01276504 -0.16564731  0.06666622\n",
      "  0.18670857  0.01828051  0.02224334 -0.05091519 -0.27981865 -0.12675273\n",
      " -0.11990847 -0.01573737 -0.16134308 -0.01927379 -0.00865242  0.12576471\n",
      "  0.19613713  0.17005457  0.17320675 -0.01050976  0.01764881  0.04085372\n",
      "  0.04331783  0.28796768 -0.25209022  0.12388169  0.21243362  0.23324586\n",
      "  0.0256233  -0.00595269  0.17059362  0.1770871   0.02421053  0.17733786\n",
      "  0.15977769  0.04152994 -0.16492638 -0.11093237  0.17105602  0.10317292\n",
      "  0.14795333  0.0381268  -0.14156187  0.02163379  0.0998509   0.20085384\n",
      "  0.277614    0.05029691  0.27947828 -0.3695819  -0.16065842  0.11013207\n",
      " -0.12463952 -0.30308136  0.11445334  0.01290529]\n",
      "----------------------------------------------------------------------\n",
      "Star_Wars_(film):\n",
      "[-0.22286369 -0.07771698  0.13737158  0.25816756  0.05800481 -0.40599036\n",
      "  0.25452587  0.37147665 -0.23358819 -0.359439   -0.03659995 -0.456516\n",
      "  0.0186801  -0.099283   -0.03439788 -0.11997899  0.1919476  -0.03049156\n",
      " -0.04636606 -0.2711617  -0.04168441  0.19818024  0.11005859 -0.18331389\n",
      " -0.11423494  0.10936803 -0.2584523   0.08505475 -0.2232475  -0.18001695\n",
      " -0.12842517  0.06126176 -0.10462387  0.15281478 -0.09715433  0.11722895\n",
      " -0.19990546 -0.10079166 -0.19501224 -0.1668666   0.13183026 -0.12114891\n",
      " -0.3741733  -0.06178337  0.13124034  0.06186696 -0.19635585  0.0813958\n",
      "  0.06039665  0.06930235  0.18325324  0.07799317 -0.11125115 -0.05606564\n",
      " -0.13205752 -0.05157027 -0.0229142  -0.05969359 -0.09241469  0.14133768\n",
      "  0.07262528  0.18915217  0.09106343 -0.15315188 -0.12288965  0.2601762\n",
      " -0.13735451  0.13276456 -0.13592897  0.10305952  0.23616509  0.11928523\n",
      "  0.15867762 -0.02831049  0.10905993  0.18245582  0.0348682   0.12127325\n",
      "  0.09029794 -0.0970543  -0.08137515 -0.0794568   0.10003465  0.02839097\n",
      "  0.06439324  0.12497001 -0.11479025  0.07093147  0.05647426  0.05551123\n",
      "  0.28904563  0.1125069   0.3612297  -0.20838605 -0.11534982  0.02541269\n",
      " -0.02772571 -0.28577566  0.12078474 -0.112137  ]\n",
      "----------------------------------------------------------------------\n",
      "Star_Trek:_The_Motion_Picture:\n",
      "[-0.20754845 -0.16240518  0.10739093  0.25096273  0.01369092 -0.30904028\n",
      "  0.19212894  0.3487319  -0.19141783 -0.3328141  -0.00652744 -0.3728823\n",
      "  0.02181132  0.10807601  0.01595539 -0.11507545  0.2766191   0.08121665\n",
      " -0.09447724 -0.33848646 -0.15591542  0.16841911  0.15498024 -0.06676834\n",
      " -0.07017603  0.0864738  -0.25503585  0.10174976 -0.18280993 -0.23100735\n",
      " -0.22799425  0.14045402 -0.09028128  0.02930825 -0.07455562  0.07185085\n",
      " -0.19038045 -0.22569028 -0.13524051 -0.12303824  0.08017056 -0.08749165\n",
      " -0.37601906 -0.05973006  0.15774365  0.03569622 -0.16983037  0.10095608\n",
      "  0.20269014  0.05774968  0.08152462 -0.02464822 -0.23286209 -0.07614945\n",
      " -0.14219101  0.00172649 -0.15225732 -0.06106033 -0.00543797  0.1777135\n",
      "  0.20101155  0.11392016  0.19872665 -0.06738674 -0.06704822  0.1609034\n",
      " -0.05783364  0.31660396 -0.20338663  0.09826246  0.15355426  0.1743767\n",
      "  0.10564637 -0.10462645  0.14874056  0.2374649  -0.01001083  0.17623596\n",
      "  0.15915363 -0.06840133 -0.10248579 -0.13396056  0.12904657  0.06654974\n",
      "  0.13336872  0.06119683 -0.01872244 -0.03214437  0.02754651  0.14363687\n",
      "  0.31261367  0.02119816  0.2481429  -0.26763177 -0.10899754  0.03912203\n",
      " -0.1303365  -0.34640834  0.08641011  0.01410962]\n",
      "----------------------------------------------------------------------\n",
      "Frozen_(2013_film):\n",
      "[-0.2910905  -0.00296889  0.10087911  0.20026682 -0.02070053 -0.40921587\n",
      "  0.22658059  0.31957445 -0.2669241  -0.34994105 -0.0317675  -0.4329939\n",
      " -0.00047264 -0.08726367  0.00689195 -0.05013021  0.2232935   0.0072758\n",
      " -0.14342014 -0.341734   -0.05885264  0.13090862  0.17808309 -0.1294975\n",
      " -0.07620565  0.12329472 -0.23053463  0.17673808 -0.20533718 -0.30973226\n",
      " -0.18634899  0.04400396  0.01113985 -0.05809729 -0.1203858   0.0826963\n",
      " -0.16984433 -0.16377161 -0.07362659 -0.18338898  0.09325089 -0.0913506\n",
      " -0.35449252 -0.04973572  0.16466403  0.03055263 -0.29890227 -0.01418801\n",
      "  0.1491594   0.09556017  0.06248447 -0.00819749 -0.20589858 -0.15126131\n",
      " -0.09091805 -0.05000912 -0.08402928 -0.07541077 -0.03579761  0.1105806\n",
      "  0.10203223  0.1881247   0.16062246 -0.07464466 -0.0599127   0.14171502\n",
      " -0.12060801  0.34616107 -0.18198024  0.08262248  0.30214137  0.16447839\n",
      "  0.06662672 -0.01725485  0.08099915  0.22103785 -0.05195347  0.22757143\n",
      "  0.11386331 -0.05284346 -0.07021231 -0.09851154  0.1387059   0.03128777\n",
      "  0.05755701  0.07008766 -0.19560485  0.07072254  0.03713816  0.11966262\n",
      "  0.23388398 -0.02474289  0.23667803 -0.3075251  -0.11061884  0.05638613\n",
      " -0.01665395 -0.22422516  0.11463153 -0.13485922]\n",
      "----------------------------------------------------------------------\n",
      "Black_Panther_(film):\n",
      "[-0.24682732 -0.07901904  0.10193818  0.19432265 -0.04872708 -0.43649185\n",
      "  0.22429127  0.31373686 -0.27292988 -0.32049495 -0.01474946 -0.45837903\n",
      "  0.00694238 -0.03907053 -0.03782634 -0.02559916  0.21942562 -0.02917036\n",
      " -0.07403909 -0.3505452  -0.02707532  0.1583125   0.09979574 -0.09284431\n",
      " -0.10204135  0.11369815 -0.26171756  0.14515902 -0.15941057 -0.18826886\n",
      " -0.1581336   0.09537895 -0.04547574  0.03860197 -0.11743318  0.05817682\n",
      " -0.16228805 -0.2597221  -0.13527411 -0.20275454  0.11429542 -0.05454786\n",
      " -0.31870478 -0.10819612  0.17665303  0.01357709 -0.20189025  0.11617552\n",
      "  0.12161523  0.0269473   0.11599099  0.06167894 -0.15302639 -0.05141043\n",
      " -0.13500674 -0.0464558  -0.1276007   0.00871568 -0.02105912  0.08257141\n",
      "  0.11322697  0.17091832  0.15639731 -0.08504874 -0.05270236  0.19002238\n",
      " -0.04628987  0.30488136 -0.19743033  0.06074522  0.26696903  0.14871237\n",
      "  0.1588893  -0.02759645  0.11909054  0.25576308  0.02410907  0.17427334\n",
      "  0.13079107 -0.04415289 -0.10401565 -0.09964487  0.06913999  0.03024324\n",
      "  0.02827954  0.06374809 -0.07431592  0.05977161  0.00429987  0.0745925\n",
      "  0.20201276  0.10637521  0.31166416 -0.23169933 -0.10940172  0.02206502\n",
      "  0.01605379 -0.21743588  0.0909903  -0.08293185]\n",
      "----------------------------------------------------------------------\n",
      "The_Cabinet_of_Dr._Caligari:\n",
      "[-0.20906359 -0.05406054  0.15688664  0.179455   -0.00053048 -0.36887774\n",
      "  0.27647388  0.33932522 -0.14514564 -0.2562684  -0.0944135  -0.3154463\n",
      "  0.04902262  0.07295351 -0.02547365  0.00419855  0.33989444  0.08141671\n",
      " -0.06922316 -0.3688186  -0.16394062  0.17565161  0.10472779 -0.03407541\n",
      " -0.10715117  0.15099534 -0.26806265  0.07851252 -0.18646233 -0.143873\n",
      " -0.17833662  0.07414761 -0.09664404  0.01406814 -0.13116072  0.07369553\n",
      " -0.0506975  -0.24733146 -0.08563679 -0.09584975 -0.02133212 -0.09650885\n",
      " -0.3007754  -0.18019298  0.1519327   0.00547512 -0.22551732 -0.01070793\n",
      "  0.22639903  0.12350124  0.12888102 -0.0338372  -0.25320673 -0.11456051\n",
      " -0.09957593  0.00595337 -0.15174492 -0.06299735 -0.0100896   0.21204047\n",
      "  0.15450373  0.05666995  0.18025646 -0.03155873 -0.07967637  0.14666434\n",
      " -0.09958391  0.25582495 -0.29022712  0.07478987  0.16227902  0.20857629\n",
      "  0.09632541 -0.06636734  0.08845964  0.2679758   0.00723239  0.12277488\n",
      "  0.19246404  0.00345315 -0.20059    -0.10016883  0.15959002  0.06805664\n",
      "  0.01821249 -0.01772195 -0.0535332   0.01348321  0.00421929  0.15103684\n",
      "  0.13964322 -0.00939034  0.23522936 -0.31624493  0.02545664  0.12234701\n",
      " -0.07995569 -0.30218625  0.12922494  0.03269201]\n",
      "----------------------------------------------------------------------\n",
      "The_Shining_(film):\n",
      "[-0.20695202 -0.19952019  0.13799219  0.2810889  -0.03303516 -0.5301606\n",
      "  0.24294762  0.29376593 -0.23855695 -0.29197186 -0.0638638  -0.4091363\n",
      " -0.03832992 -0.07943062 -0.0592225  -0.01122311  0.30148724 -0.02732249\n",
      " -0.03151285 -0.29833227 -0.1581456   0.22484909  0.05869353 -0.09750679\n",
      " -0.1348358   0.1534628  -0.2786792   0.0956184  -0.1899868  -0.17589898\n",
      " -0.14377005  0.13568588 -0.11624629  0.05575523 -0.13747516  0.04457514\n",
      " -0.13811204 -0.2516402  -0.18644167 -0.16581203  0.02439439 -0.11705925\n",
      " -0.2573431  -0.1390841   0.19202588  0.05406073 -0.18685089  0.07468072\n",
      "  0.1049189   0.13446715  0.12725165 -0.00736427 -0.18935798 -0.11951689\n",
      " -0.14511058 -0.12183637 -0.11317895 -0.01978198  0.000624    0.1283024\n",
      "  0.06528949  0.15634644  0.1457556  -0.07733136 -0.08825655  0.23757753\n",
      " -0.05928952  0.20237772 -0.2111085   0.10383832  0.14981386  0.26685393\n",
      "  0.1160089  -0.04945882  0.14958352  0.21691194  0.05755327  0.10038857\n",
      "  0.1541389   0.01030222 -0.11756684 -0.0841555   0.11952131 -0.03150313\n",
      "  0.02540461  0.01911557 -0.13875185  0.05144583  0.0810132   0.15463221\n",
      "  0.1814239   0.09099299  0.3426     -0.23278248 -0.04602626  0.04348228\n",
      " -0.09491929 -0.28114197  0.1460606  -0.03367523]\n",
      "----------------------------------------------------------------------\n",
      "Scream_(franchise):\n",
      "[-0.24748638 -0.08342341  0.12858     0.23814373 -0.06783075 -0.4263952\n",
      "  0.21908683  0.34090716 -0.20038052 -0.35841668  0.01842616 -0.4047409\n",
      "  0.04458854 -0.02589317  0.03541034 -0.11977256  0.2837722  -0.00760888\n",
      " -0.03145996 -0.29783943 -0.13734983  0.09445532  0.0555195  -0.10345895\n",
      "  0.04056128  0.13603316 -0.32562795  0.08856278 -0.1850087  -0.19357483\n",
      " -0.16269991  0.15853173 -0.06008102 -0.00228248 -0.11087161  0.09376851\n",
      " -0.18860969 -0.2207604  -0.14733848 -0.08032913  0.05964065 -0.03537865\n",
      " -0.3287092  -0.09038555  0.12919359  0.04103951 -0.19109702  0.07084304\n",
      "  0.16654052  0.00584313  0.14860904  0.05397092 -0.22964627 -0.05368434\n",
      " -0.11568175  0.0122524  -0.11630409 -0.0641245   0.04852098  0.13642764\n",
      "  0.18685459  0.17793876  0.21566156 -0.11659814 -0.0927955   0.17947416\n",
      " -0.03562503  0.30686432 -0.20735025  0.1413093   0.1582551   0.23818289\n",
      " -0.00893567 -0.04910308  0.18091321  0.17002016 -0.00130603  0.13348787\n",
      "  0.11815325  0.00764735 -0.0982355  -0.10251648  0.24167953  0.11948494\n",
      "  0.20071305  0.08707573 -0.08404222  0.07135321  0.07183927  0.21236967\n",
      "  0.21227561  0.07067425  0.25579542 -0.29889253 -0.15796627  0.07572291\n",
      " -0.06511874 -0.35883808  0.11563317  0.0571267 ]\n",
      "----------------------------------------------------------------------\n",
      "Batman_v_Superman:_Dawn_of_Justice:\n",
      "[-0.27287567 -0.11031637  0.06664279  0.24969819 -0.02666281 -0.40236092\n",
      "  0.23177171  0.33891773 -0.29033726 -0.3044314  -0.04921626 -0.464053\n",
      "  0.03675848 -0.10098118  0.01255507 -0.09242551  0.21831597  0.00081242\n",
      " -0.04073521 -0.34989655 -0.1660337   0.11308895  0.10473741 -0.06928772\n",
      " -0.13938004  0.1096938  -0.27184078  0.12672716 -0.18375933 -0.22766012\n",
      " -0.1145412   0.13439621 -0.03759752  0.08034248 -0.15359776  0.09643246\n",
      " -0.16699512 -0.20062715 -0.13551192 -0.15947598  0.12225248 -0.06276389\n",
      " -0.29163045 -0.0558407   0.14746775  0.03474335 -0.20236677  0.08050452\n",
      "  0.12159815  0.01597666  0.08541372  0.14290228 -0.16953363 -0.08892027\n",
      " -0.12144607  0.00732427 -0.14950162 -0.02366933 -0.00063013  0.14402367\n",
      "  0.16824636  0.135503    0.15793882 -0.15843958 -0.09768459  0.18817079\n",
      " -0.11862361  0.27090615 -0.21766345  0.10569993  0.18302958  0.17062205\n",
      "  0.05796541 -0.03520714  0.16310851  0.2915584   0.00745117  0.15308672\n",
      "  0.0996004  -0.07515903 -0.12239155 -0.11444688  0.05947995  0.07937361\n",
      "  0.08366124  0.04424738 -0.14879107  0.00332388  0.02981686  0.09492344\n",
      "  0.21585947  0.07317398  0.29151142 -0.26096332 -0.04906407  0.02334859\n",
      " -0.07969089 -0.25072083  0.09605885 -0.05346368]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "###  2. Use the first paragraph’s words and take an average on these embeddings  ###\n",
    "####################################################################################\n",
    "def find_first_paragraph(text: str):\n",
    "    return text.split(\"\\n\")[0]\n",
    "\n",
    "def average_first_para_words() -> dict:\n",
    "    doc_embeddings = {}\n",
    "    for line in train_data_list:\n",
    "        doc_title = line[\"title\"]\n",
    "        valid_word_embeddings = [model.wv[word] for word in utils.simple_preprocess(find_first_paragraph(line[\"text\"])) if word in model.wv]\n",
    "        # since the number of words in the first paragraph is so small, it may occur `ZeroDivisonError` in the computation, here I use a \n",
    "        # try-except flow to handle this exception\n",
    "        try:\n",
    "            doc_embedding = sum(valid_word_embeddings) / len(valid_word_embeddings)\n",
    "        except:\n",
    "            doc_embedding = [0 for _ in range(len(valid_word_embeddings))]\n",
    "        doc_embeddings[doc_title] = doc_embedding\n",
    "\n",
    "    return doc_embeddings\n",
    "\n",
    "average_first_para_words_embedding = average_first_para_words()\n",
    "print_document_embeddings(average_first_para_words_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b65aeca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citizen_Kane:\n",
      "[ 4.7364583  -0.4052419  -3.325441   -0.00980055  2.2403915  -0.38089612\n",
      " -1.7430489   1.9974115  -0.34079576 -1.8416704   4.6921206  -0.83687544\n",
      " -0.5875558  -2.5266826  -1.5581137  -1.9378619   0.41974545 -0.20577174\n",
      " -0.233671   -0.5592773  -1.2667687  -2.4095256   2.1755638   1.3998338\n",
      " -0.37822956 -2.763966    0.19035669  0.38866246  0.65558684 -1.5939412\n",
      "  0.19869779 -0.18014884 -0.6731388   2.7298503  -1.7768732  -1.2059423\n",
      "  0.71505576 -4.7347097  -3.6729484   3.0021446   1.696856   -2.112462\n",
      "  2.5512295  -4.776504    1.9631578  -2.9360864   2.0496993   0.9342798\n",
      "  4.219702   -0.23724927  3.6270535   5.600189    2.2999876  -1.7758241\n",
      "  3.6775427  -1.3034785   1.980849    3.5197618  -2.7026672   2.130448\n",
      " -4.533793    3.3864272   3.861147   -3.0859003   1.342131    0.91237205\n",
      "  2.8728738  -0.33080804 -3.0298274   0.22950499 -3.574138    0.13689718\n",
      " -1.1283343  -1.7133118  -1.3141903   1.9607078   4.1194477  -7.1288643\n",
      "  2.9881096   4.2724433  -3.0735712   3.6197658  -2.979809    1.4588909\n",
      " -3.0373027   3.7175872  -3.5243773   2.0302942   0.4169705   3.070596\n",
      " -2.0672908   1.8382989  -2.3832765  -1.0710058   1.5291997   0.01818306\n",
      "  1.7129383  -1.2153369  -1.1145251   1.142655  ]\n",
      "----------------------------------------------------------------------\n",
      "It_(2017_film):\n",
      "[ 2.5762420e+00 -3.0070870e+00  2.9465958e-01  4.4521725e-01\n",
      " -6.3478723e+00  3.0389681e+00 -8.0323815e-01  1.2425529e+00\n",
      "  1.4933391e+00  2.0398836e+00  4.3864832e+00  3.6044237e-01\n",
      "  1.2759870e+00 -3.2289956e+00  1.1855440e+00 -4.3904033e+00\n",
      " -2.8487760e-01  3.5440645e+00 -1.6935631e+00  4.0130467e+00\n",
      "  1.9537888e+00  2.1499183e+00  3.5127091e+00  1.7404698e+00\n",
      " -5.9015884e+00 -9.9496621e-01 -5.9815774e+00 -1.2110173e+00\n",
      "  2.2558606e+00 -3.7807484e+00 -4.4740069e-01  3.2194595e+00\n",
      " -2.2429276e+00  4.8698587e+00  1.3827796e+00 -7.8852463e-01\n",
      "  1.7064974e+00 -2.7793362e+00 -5.5826688e+00  9.8200703e-01\n",
      "  4.1094003e+00 -1.1957613e+00  9.3456298e-01 -7.5029159e+00\n",
      " -8.5132843e-01 -5.1567078e+00  5.8231645e+00  1.6705650e+00\n",
      " -1.3423033e-01 -3.2440026e+00 -1.4258068e+00  1.5836054e+00\n",
      "  3.1673901e+00  7.1917439e-01 -1.3198087e+00 -2.5395358e+00\n",
      "  1.5603726e-01  2.5102875e+00  2.0588808e+00 -4.8627179e-02\n",
      "  6.4214649e+00  4.7487116e-01  2.1648307e-01 -6.2021822e-01\n",
      " -9.2172700e-01  3.9184770e-01 -5.1601853e+00 -1.6262362e+00\n",
      " -1.6129337e-01 -9.8687285e-01 -4.3851819e+00  6.9535929e-01\n",
      "  1.0770222e+00 -1.5505236e+00 -1.2291700e+00  4.1833119e+00\n",
      "  3.5458903e+00 -1.9192209e+00  1.6059369e+00 -3.1796672e+00\n",
      "  2.7603605e-01  3.0468087e+00 -2.6715100e+00 -2.2026391e+00\n",
      " -2.6110528e+00  4.9407125e+00 -1.9392761e+00 -4.8825994e-01\n",
      " -3.0013581e-03  1.8416053e+00 -2.1399550e+00  3.1460246e-01\n",
      " -3.6760134e-01  1.1130313e+00 -7.0277762e-01  4.1908460e+00\n",
      "  2.1898727e+00  2.1782565e-01 -2.8758595e+00 -5.9224278e-01]\n",
      "----------------------------------------------------------------------\n",
      "Star_Wars_(film):\n",
      "[ 1.8328334  -3.3807511  -1.2537268   0.02136908  2.10905    -2.5330832\n",
      " -2.3242028   1.8067997  -1.7123842   1.0436283   4.26382     0.23929974\n",
      "  2.0541396  -2.817503    0.9202383  -2.3568857   0.6214375   1.1192687\n",
      " -1.7923368   4.036558    0.6271238  -0.87272537  1.8795805   4.4326243\n",
      " -2.7257726  -1.4553864  -0.758092   -0.63179666  0.21693836 -0.23898546\n",
      " -2.5995421   2.8470376  -2.5532396  -1.8153828   2.7028842  -2.3015378\n",
      "  0.83096296 -3.2259147  -3.303113   -1.3914455   2.160764    1.9061568\n",
      "  0.9165357  -5.194678   -2.2332687  -3.1744914   1.7592599   4.086403\n",
      "  1.6009606   1.2267988   1.5406103  -1.3434788  -1.2326709  -2.728843\n",
      "  2.0905828   1.6841756   0.70489585  0.70963854  0.05188334  2.3166738\n",
      "  0.0579366   2.2088268   4.2881713  -3.6229239  -1.5966233   0.7318061\n",
      " -1.2182899  -1.2975277  -0.8975153   2.853197   -3.490023   -1.5049044\n",
      " -1.7942885  -3.972377    0.02319414  3.677101   -0.16748837 -5.4664392\n",
      "  5.119894    3.196774   -2.4154298   3.392847   -3.0465343  -2.8802955\n",
      " -6.891879    3.411174   -3.6643853   0.4427329  -1.189682   -0.44656193\n",
      " -2.6397555   1.4117905  -1.8254571  -2.736207    1.2223749   1.9566959\n",
      "  1.417544    1.8923768  -2.482482    0.04697172]\n",
      "----------------------------------------------------------------------\n",
      "Star_Trek:_The_Motion_Picture:\n",
      "[-0.11794189 -1.343907   -2.4429374   0.5738409   1.0909175  -4.609533\n",
      "  0.78796965  1.7086742  -0.49067116 -0.10741518  4.019564   -2.1857793\n",
      " -0.8559849  -1.0060859  -1.3525217  -3.0139644   0.63532525 -0.24458835\n",
      " -2.8136797   1.9204727  -1.1348207   0.75642556  0.9111773   4.1688347\n",
      " -0.54312366  1.2014518  -2.1284971   1.262725    1.2646638  -1.7096118\n",
      " -2.98099     1.8664576  -4.061105    2.7799394   0.9203462  -1.4259046\n",
      "  2.9877126  -5.173812   -7.9892554   3.2695346   3.296429    2.7219377\n",
      " -0.9163386  -4.2017303   3.8465552  -3.4245617   1.4432366   4.124563\n",
      "  3.5723767  -0.19885752  1.6086682  -0.0872178  -2.279993   -2.9380393\n",
      "  1.4049846  -0.7756029   4.9203424   2.6721919  -6.643573    0.4120766\n",
      "  0.14541858  3.3673854   2.2514794  -2.674461   -1.9607856   1.1595696\n",
      " -1.3414123  -2.1646438  -0.7248248   2.8349748  -2.3917718   0.08145702\n",
      "  0.5033974  -6.091912   -1.4594673   1.6407627   2.9895456  -1.2708939\n",
      "  3.3011296   3.3328643  -2.0160766   0.0401709  -2.145644    0.6902419\n",
      " -5.745411    5.2533627  -3.559627   -0.40583292 -0.5136047  -0.4518496\n",
      "  0.8505528   2.8359041  -5.167799    0.61970055  1.6077001   0.6478899\n",
      "  2.328397    2.5857253  -1.7199473   3.4232683 ]\n",
      "----------------------------------------------------------------------\n",
      "Frozen_(2013_film):\n",
      "[-0.7293143  -2.5117152  -1.019619   -0.57726127 -3.731552   -0.9701178\n",
      " -2.1939456   0.78542167 -2.5868454   1.6898377   4.9817452   0.8208\n",
      "  2.8147085  -2.23806     0.32455084 -3.320687   -0.86519873  2.7523386\n",
      " -1.2691772   6.9132347   1.0620824   4.732332    0.63070303  2.1233366\n",
      " -4.990067   -2.427126   -0.48450756 -1.4473488   0.23756218 -1.3767517\n",
      "  1.7644145   1.8486133  -2.9901688   1.899337    0.35980484 -1.9897356\n",
      " -1.801861   -7.8436303  -3.4272702   0.511013    1.7492769  -1.4817837\n",
      "  1.2581844  -4.284178   -1.9550985  -3.8339076   2.6086345   3.868867\n",
      " -0.36535752  0.57376856  0.15206489 -0.9376881   0.43175557 -0.19654922\n",
      " -1.210616   -1.6203932   3.2584138   2.4641237  -0.1178431   3.7379081\n",
      "  1.122771    1.2471895   1.247702   -2.4900606   1.6448679  -0.76819026\n",
      " -4.6395206   0.73136353 -1.8716718   0.36872804 -1.8035227  -1.045013\n",
      " -1.2965982  -0.3703823  -0.1995693   4.550953    0.20418072 -5.4257207\n",
      "  1.7572018  -1.1153679  -2.0864208   1.6949946   0.591537   -4.286948\n",
      " -1.5825177   0.12536044 -1.705695   -1.4984847   1.5158358  -0.06987508\n",
      " -2.1887372   0.920901    0.24796474  0.40807027  0.13397592  3.9120097\n",
      " -1.4413635  -0.50568175 -1.6930807   2.0006099 ]\n",
      "----------------------------------------------------------------------\n",
      "Black_Panther_(film):\n",
      "[ 0.52401793 -4.2416654  -0.6697218   3.0472333  -4.670045    0.51067126\n",
      " -1.5371004   2.4362407   0.57032245 -0.31620628  5.094093    2.0938466\n",
      "  0.13990335 -3.2768936   0.76275015 -6.796844   -2.1892257   0.6880497\n",
      " -0.65042824  4.0483785   4.0734262   2.8919535   0.71443164 -0.09496983\n",
      " -5.9928083  -0.9414991   0.04534418 -3.0123155  -0.54506874 -4.810837\n",
      "  0.46384224 -1.6782787  -1.6941878   4.5320616   1.1152014  -4.3315024\n",
      " -0.36228684 -1.3557082  -5.258441    1.9620374   0.76979387  1.7674277\n",
      " -2.3832436  -7.7143097  -0.64926296 -6.016212    5.246578    4.136611\n",
      "  0.8723407  -1.332474   -0.33326784  1.1658285  -0.8394661  -0.07850641\n",
      " -0.711967    0.7304993   0.14138834  3.4739108  -0.22114307 -1.2019666\n",
      "  2.364208    0.66237676  0.24805805 -0.8940708  -1.0822233   1.0902841\n",
      " -1.089382    2.702049    1.7038808  -1.2983447  -2.3114522  -0.35900742\n",
      "  0.23292777 -0.9549715  -1.2148031   2.1735425  -0.5925707  -0.95649636\n",
      "  2.487765   -0.9672295   1.0193995   2.0034213  -0.99484295 -3.2484877\n",
      " -1.5591118   3.766381   -2.4878435  -0.20616725 -1.6619182  -0.8581887\n",
      " -3.5905986   3.3757217  -0.08981645  1.8354504   0.59827393  3.576118\n",
      " -1.9833679   3.342135    1.3154659  -0.60197014]\n",
      "----------------------------------------------------------------------\n",
      "The_Cabinet_of_Dr._Caligari:\n",
      "[-1.113667   -2.1334064  -3.906122    3.5562105   1.401749   -2.902548\n",
      " -4.1973534   1.5433092  -2.8473477   2.5119014   4.2260923   0.3544738\n",
      "  2.8260112  -4.4579005  -1.2845734   0.5964309   1.4627615  -3.5491061\n",
      " -5.1512113  -2.113778    0.22519298  0.67756176  0.6271246   3.1621912\n",
      "  1.065968   -0.6355968   2.4722953  -1.9273378  -1.0425724  -2.213028\n",
      "  1.8530716  -1.882308    1.6005129   1.2955      2.0461903  -0.09339514\n",
      " -4.9968486  -5.3546515  -4.184033    0.9721968   4.1544895  -2.377594\n",
      "  0.3306111   0.57548743  0.6381532  -5.076487    2.3402314  -1.1521454\n",
      "  2.5448625   0.596108   -0.694083    2.389415    2.2223856  -1.0998231\n",
      "  6.663529    3.2086573  -0.2143325   1.5479703  -3.4755077   1.0492029\n",
      "  0.06845161  2.1641417   2.5873954  -1.2370509   1.2373655   0.6697986\n",
      "  2.3084748   3.4524217  -5.2746143  -1.9999908  -3.6022198   0.6466706\n",
      " -1.4397897  -1.2306092   2.4380863   2.4313703   3.953965   -3.1607547\n",
      "  2.33636    -0.23744488 -2.5219758   1.2057111  -1.9855242  -0.4719659\n",
      " -4.042099    2.2185264  -0.09739543  0.05770502  0.2582502   0.38282543\n",
      " -1.9121677   1.8120531  -0.57687217 -1.3353966   3.7576764  -0.7567812\n",
      "  2.8767855   2.414931    0.44083148  1.2210281 ]\n",
      "----------------------------------------------------------------------\n",
      "The_Shining_(film):\n",
      "[ 3.0029032   1.8369642  -1.9206545   1.0784519  -2.4817162   0.2771918\n",
      " -1.5615839   1.2462378  -0.56499237  0.78730035  4.5283227  -0.41308054\n",
      " -1.4610845  -1.0409987   0.88067174 -2.9644647   1.8053013   0.8781667\n",
      " -2.8404994   0.28064162  0.29994196  0.28371942  2.6513846   0.7572067\n",
      " -5.565015   -0.09708744 -3.0282888   0.18105182  3.5768821  -2.618661\n",
      " -0.8248565   4.318681    1.189474    4.230168   -0.6816795  -0.18495464\n",
      " -3.5454512  -2.444578   -3.242602   -0.2773601  -0.45074096 -0.79236275\n",
      "  3.5193262  -4.648546    1.8244212  -3.109267    2.2925096   1.01651\n",
      "  2.610777    1.2066423  -0.04915001  3.6321464   3.6284096  -0.13578546\n",
      "  1.5954062   0.6938789   1.721734    2.341472    1.8913292  -0.4644701\n",
      "  1.7002012   0.79185075  0.9729512  -1.2014574  -0.34826916 -0.01648409\n",
      "  1.6777163   0.6740231  -1.4032943  -1.9454055  -1.0179147   0.32764035\n",
      " -2.0108337  -3.5957844  -0.09112144  3.0890083   2.2921019  -1.7001108\n",
      "  2.0235274  -1.917618    1.8036525   2.4252782  -4.145048   -1.186901\n",
      " -5.0040307   3.0824513  -1.2148012   4.194105   -0.19881012 -1.7657156\n",
      " -0.54996103  1.874072   -5.7630544  -0.7673258   4.172119    0.69023603\n",
      "  2.3267324   1.6646135  -2.0273364   4.0272913 ]\n",
      "----------------------------------------------------------------------\n",
      "Scream_(franchise):\n",
      "[ 1.47214925e+00 -2.53718066e+00 -3.26810479e+00  6.42748952e-01\n",
      " -2.09977818e+00 -4.32492524e-01 -3.81326675e+00  5.61065435e-01\n",
      " -9.51140046e-01 -3.15489221e+00  5.68278599e+00  1.43791288e-01\n",
      "  6.51610255e-01  1.76152217e+00 -2.50147730e-02 -1.17134750e+00\n",
      "  1.15694106e-01 -5.25761366e-01  3.62394929e-01  7.00296640e+00\n",
      "  1.90639853e-01  3.12135124e+00  5.23578346e-01  5.14877796e+00\n",
      " -5.25191259e+00  1.20655322e+00 -6.01557016e-01 -4.77725792e+00\n",
      "  6.48726448e-02 -4.74970484e+00 -1.70364410e-01  1.02833986e+00\n",
      "  4.09096670e+00  2.44744515e+00 -1.71556747e+00  7.17102706e-01\n",
      " -2.89133215e+00 -4.84799528e+00 -5.74760103e+00  2.71918201e+00\n",
      "  1.88114002e-01  9.02280629e-01 -1.41439527e-01 -4.51204872e+00\n",
      "  2.22792888e+00 -3.64105463e+00  3.58906388e+00  2.70880651e+00\n",
      "  6.12193942e-01 -8.94255459e-01  1.28538907e+00  4.47835445e+00\n",
      " -5.81561685e-01  4.86178070e-01  1.72329211e+00 -1.18679106e+00\n",
      " -2.64824510e-01  1.06235409e+00  1.31292477e-01  2.65971269e-03\n",
      "  1.23088980e+00  2.98818374e+00 -9.51359808e-01  2.21527085e-01\n",
      " -6.93764910e-02 -2.96936965e+00 -3.87379199e-01 -3.22590828e+00\n",
      " -4.32969236e+00  1.51832139e+00 -2.57999849e+00 -1.48984075e+00\n",
      " -3.95882320e+00 -4.22317982e+00  1.71863794e+00  1.57094312e+00\n",
      "  1.12654269e+00  9.37417984e-01  2.90446663e+00 -1.72068387e-01\n",
      " -1.45335650e+00  5.61621952e+00 -1.60109174e+00 -2.55329013e+00\n",
      " -4.01969147e+00  4.48841238e+00 -6.68419361e-01 -1.89031005e+00\n",
      " -2.32011342e+00 -3.08716148e-01 -3.86471939e+00  2.14123416e+00\n",
      " -6.98898888e+00 -1.47753394e+00 -7.71631598e-02  5.88387585e+00\n",
      " -1.12000453e+00  1.35445964e+00  1.32931924e+00  4.23665953e+00]\n",
      "----------------------------------------------------------------------\n",
      "Batman_v_Superman:_Dawn_of_Justice:\n",
      "[ 2.4887204  -3.8853126  -1.7117105   0.2957581  -4.066885    3.9280834\n",
      " -3.4319544  -0.22319183  1.3134779   1.3385369   6.7879157   1.7069702\n",
      "  0.5924982  -3.2729099   2.083817   -4.4435625   0.71408224  1.7552065\n",
      " -2.8009799   4.484021    3.0282583   1.6647727   1.3620658   3.4633617\n",
      " -4.8772554  -0.9026192  -2.8440282  -3.3872      0.5019285  -4.673942\n",
      "  1.3897748   3.5250838   0.5971796   2.2623103   1.528277    0.573177\n",
      "  1.8521601  -4.8336368  -1.2277294   1.9073762   0.47056317  1.64512\n",
      " -0.02456005 -5.392387   -2.3722622  -2.7518086   5.197352    3.7116954\n",
      " -1.4081341  -1.9292939   1.6736066   0.52835876  2.2897074   2.0477917\n",
      " -0.01956686  0.6465293  -1.8040913   4.157407    0.607598   -1.9766246\n",
      "  3.533878    2.0183759   1.607292    0.19435506  0.50778276  0.29356202\n",
      " -1.493871   -1.5576733   0.695366   -1.0073779  -5.6211767  -2.1123025\n",
      " -0.19586785 -1.2523893  -2.3434594   6.9976964   1.900087   -2.276444\n",
      "  1.781308   -1.6057081   1.2337432   5.612181   -2.175608   -2.3979442\n",
      " -1.8314565   1.196283    0.4225002   2.9129045  -0.42523998  0.14066483\n",
      " -2.2368448   2.4969907  -1.3602787   0.78133935  1.1248444   4.823167\n",
      " -1.027802    1.7118112   0.46227375 -4.3229847 ]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "###             3. Use the doc2vec algorithm to present each document            ###\n",
    "####################################################################################\n",
    "def build_doc2vec() -> Doc2Vec:\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=5, epochs=10)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model\n",
    "\n",
    "def print_doc2vec_embedding(model: Doc2Vec, display: int=10) -> None:\n",
    "    for index, line in enumerate(train_data_list):\n",
    "        if index >= display:\n",
    "            break\n",
    "        print(\"{}:\\n{}\".format(line[\"title\"], model.infer_vector(line[\"text\"].split())))\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "tagged_data = [TaggedDocument(words=doc.split(), tags=[str(i)]) for i, doc in enumerate([line[\"text\"] for line in train_data_list])]\n",
    "\n",
    "doc_model = build_doc2vec()\n",
    "print_doc2vec_embedding(doc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091195ab-834c-4184-a8f2-490cd26b7ff4",
   "metadata": {},
   "source": [
    "### Task 4 Build classifier to test docs\n",
    "> Build softmax regression model to classifier testing documents based on these training doc embeddings. Does it getting better than Naive Bayes'? (You have 3 models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c43b8e-603f-4352-982c-f90d85e9f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206de2a-6d96-4016-b74e-4a08da2e1cab",
   "metadata": {},
   "source": [
    "### Task 5 Use t-SNE to project doc vectors\n",
    "\n",
    "> Use t-SNE to project training document embeddings into 2d and plot them out for each of the above choices. Each point should have a specific color (represent a particular cluster). You may need to try different parameters of t-SNE. One can find more details about t-SNE in this [excellent article](https://distill.pub/2016/misread-tsne/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fe1b9-0650-438c-ad75-49e6632bf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
