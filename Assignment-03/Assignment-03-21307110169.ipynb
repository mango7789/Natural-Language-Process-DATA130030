{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Before your go ----\n",
    "# 1. Rename Assignment-03-###.ipynb where ### is your student ID.\n",
    "# 2. The deadline of Assignment-03 is 23:59pm, 06-05-2024\n",
    "\n",
    "\n",
    "# --- Explore HMM POS Taggers using Brown corpus ---\n",
    "# In this assignment, you will explore three taggers for a Brown corpus.\n",
    "# import your packages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb55db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 1 --- Load and explore your data ---\n",
    "# 1). load train/test samples from Brown corpus files, brown-train.txt, brown-test.txt.\n",
    "# 2). load all 12 tags from brown-tag.txt and print it out\n",
    "# 3). counting how many sentences and words in both train and test datasets.\n",
    "# 4). for each tag, counting how many words in train and test. e.g, tag1: [count_tr, count_te]\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d633df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 --- Method 1: Build a baseline method, namely, the most frequent tagger ---\n",
    "#     If you can recall, we introduced a strong baseline method (See Dan's book in \n",
    "# https://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf Page 164.),\n",
    "#     where we label each word by using the most frequent-used tag associated with it.\n",
    "# 1). find the most frequent class label for each word in the training data.\n",
    "#     For example, {tr_word_1:tag_1,tr_word_2:tag_2,...}\n",
    "# 2). use your built method to predict tags for both train and test datasets.\n",
    "#     You should print out two values: the accuracies of train and test samples.\n",
    "#     You would expect that the accuracy on train will be > 9.0 (but never = 1.0) and higher than on test.\n",
    "\n",
    "# Notice: since there are unkown words in test samples. \n",
    "#  Following ways could handle this (choose one or create your own): \n",
    "#  1). mark all words that appear only once in the data with a \"UNK-x\" tag\n",
    "#  2). tag every out-of-vocabulary word with the majority tag among all training samples.\n",
    "#  3). find more methods in https://github.com/Adamouization/POS-Tagging-and-Unknown-Words\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38802c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 --- Method 2: Build an HMM tagger ---\n",
    "# 1) You should use nltk.tag.HiddenMarkovModelTagger to build an HMM tagger.\n",
    "#    It has parameters: symbols, states, transitions, outputs, priors, transform (ignore it).\n",
    "#    Specify these parameters properly. For example, you can use MLE to estimate transitions, outputs and priors.\n",
    "#    That is, MLE to estimate matrix A (transition matrix), and matrix B (output probabilites) (See. Page 8.4.3)\n",
    "# 2) After build your model, report both the accuracy of HMM tagger for train samples and test samples.\n",
    "# \n",
    "# 3) Compared with your baseline method, discuss that why your HMM tagger is better/worse than baseline method.\n",
    "\n",
    "# Notice: You may also need to handle unknown words just like Task 2.\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ab053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 --- Method 3: Fine-tuning on BERT-base model for POS-tagging ---\n",
    "# \n",
    "# 1) You may download a BERT model (say, you choose BERT-base cased) \n",
    "#    and use tools in https://github.com/huggingface/transformers\n",
    "# \n",
    "# 2) After build your model, report both the accuracy of BERT tagger for train samples and test samples.\n",
    "# \n",
    "# 3) Compared with Method 1,2, discuss that why your BERT tagger is better/worse than these two."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
